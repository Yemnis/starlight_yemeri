# Vector Search Implementation Guide

## ðŸŽ‰ What's Implemented

Your backend now has **FULL VECTOR SEARCH** capabilities! Here's what's working:

### âœ… Features Implemented

1. **Intelligent Query Analysis**
   - Automatically detects if a query should use semantic search or traditional filters
   - Analyzes query intent (semantic vs filtered vs general)

2. **Real Vector Embeddings**
   - Generates 768-dimensional embeddings using Vertex AI
   - Fallback embedding generation for reliability
   - Stores embeddings in Firestore with metadata

3. **Cosine Similarity Search**
   - Calculates vector similarity between query and stored scenes
   - Returns most relevant scenes based on semantic meaning
   - Supports campaign filtering and confidence thresholds

4. **Hybrid Search Strategy**
   - **Vector Search**: For semantic/descriptive queries like "happy moments with products"
   - **Traditional Search**: For filtered queries like "campaign:123" or "product:iPhone"
   - **Smart Detection**: Automatically chooses the best approach

---

## ðŸ”§ Setup Required

### Step 1: Enable Google Cloud APIs

**Enable these APIs in your Google Cloud Console:**

1. **Vertex AI API** - [Enable Here](https://console.cloud.google.com/apis/library/aiplatform.googleapis.com?project=gen-lang-client-0082081331)
   - Click "ENABLE"

2. **Firestore API** - [Enable Here](https://console.cloud.google.com/apis/library/firestore.googleapis.com?project=gen-lang-client-0082081331)
   - Click "ENABLE"

3. **Cloud Storage API** - [Enable Here](https://console.cloud.google.com/apis/library/storage.googleapis.com?project=gen-lang-client-0082081331)
   - Click "ENABLE"

### Step 2: Initialize Firestore Database

1. Go to [Firestore Console](https://console.cloud.google.com/firestore?project=gen-lang-client-0082081331)
2. Click "**Create Database**"
3. Choose "**Native mode**"
4. Select location: **us-central1** (or your preferred region)
5. Start in "**Production mode**"

### Step 3: Create Cloud Storage Bucket

1. Go to [Cloud Storage](https://console.cloud.google.com/storage/browser?project=gen-lang-client-0082081331)
2. Click "**CREATE**"
3. Settings:
   - **Name**: `starlight-videos-gen-lang` (or unique name)
   - **Location**: Region â†’ `us-central1`
   - **Storage class**: Standard
   - **Access control**: Uniform
4. Click "**CREATE**"

### Step 4: Update Your `.env` File

```bash
# Your existing OpenAI key
OPENAI_API_KEY=your-openai-key-here

# Google Cloud Project (already set)
GCP_PROJECT_ID=gen-lang-client-0082081331

# Cloud Storage Bucket (from Step 3)
GCS_BUCKET=starlight-videos-gen-lang

# Service Account (already set)
GOOGLE_APPLICATION_CREDENTIALS=./config/service-account-key.json

# Server Config
PORT=3001
NODE_ENV=development
GCP_LOCATION=us-central1
VERTEX_AI_LOCATION=us-central1

# Vertex AI Models
GEMINI_NANO_BANANA_MODEL=gemini-2.0-flash-exp
GEMINI_PRO_MODEL=gemini-1.5-pro
EMBEDDING_MODEL=text-embedding-004

# CORS
FRONTEND_URL=http://localhost:5173

# Vector Search (optional - leave empty)
VECTOR_INDEX_ID=
VECTOR_INDEX_ENDPOINT=
```

---

## ðŸš€ How It Works

### Query Flow

```
User Query â†’ Query Analyzer â†’ Search Strategy Decision
                                    â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“                               â†“
            Vector Search                    Traditional Search
            (semantic queries)               (filtered queries)
                    â†“                               â†“
            Embedding Generation            Firestore Queries
                    â†“                               â†“
            Cosine Similarity               Filter Application
                    â†“                               â†“
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
                            Enrich Results
                                    â†“
                            Sorted Results
```

### Query Examples

**Vector Search (Semantic Queries):**
- âœ… "Show me happy moments with products"
- âœ… "Scenes featuring people smiling"
- âœ… "Energetic and exciting clips"
- âœ… "Calm and peaceful scenes"

**Traditional Search (Filtered Queries):**
- âœ… "campaign:abc123"
- âœ… "product:iPhone"
- âœ… "exact scene id:xyz"

### Automatic Detection

The system analyzes queries based on:
- **Keywords**: "like", "similar", "showing", "with", "about", "happy", "sad", etc.
- **Query Length**: Longer descriptive queries (>3 words) use vector search
- **Filter Syntax**: Queries with "id:", "campaign:", "product:" use traditional search

---

## ðŸ“Š Vector Search Architecture

### Embedding Storage in Firestore

```
Collection: embeddings
â”œâ”€â”€ Document: emb_scene_001
â”‚   â”œâ”€â”€ sceneId: "scene_001"
â”‚   â”œâ”€â”€ embedding: [0.123, -0.456, ...] (768 dimensions)
â”‚   â”œâ”€â”€ metadata: {
â”‚   â”‚     videoId: "video_123",
â”‚   â”‚     campaignId: "campaign_abc",
â”‚   â”‚     description: "...",
â”‚   â”‚     mood: "happy",
â”‚   â”‚     visualElements: [...]
â”‚   â”‚   }
â”‚   â”œâ”€â”€ dimension: 768
â”‚   â”œâ”€â”€ createdAt: timestamp
â”‚   â””â”€â”€ updatedAt: timestamp
```

### Scene Processing Pipeline

```
Video Upload â†’ Scene Extraction â†’ Scene Analysis
                                        â†“
                                Embedding Generation
                                        â†“
                                Store in Firestore
                                   (scenes + embeddings)
```

### Search Pipeline

```
User Query â†’ Generate Query Embedding â†’ Compare with Stored Embeddings
                                                â†“
                                        Cosine Similarity
                                                â†“
                                        Rank by Similarity
                                                â†“
                                        Return Top Results
```

---

## ðŸŽ¯ API Endpoints Using Vector Search

### Search Scenes
```bash
POST /api/search/scenes
Content-Type: application/json

{
  "query": "happy moments with products",
  "campaignId": "optional-campaign-id",
  "limit": 10,
  "filters": {
    "minConfidence": 0.7,
    "visualElements": ["person", "product"]
  }
}
```

**Response:**
```json
{
  "results": [
    {
      "scene": { ... },
      "video": { ... },
      "score": 0.892,
      "highlights": ["happy", "product", "smiling"]
    }
  ],
  "strategy": "semantic",
  "count": 10
}
```

### Find Similar Scenes
```bash
GET /api/search/scenes/:sceneId/similar?limit=5
```

---

## ðŸ” Testing Vector Search

### Test 1: Semantic Search
```bash
curl -X POST http://localhost:3001/api/search/scenes \
  -H "Content-Type: application/json" \
  -d '{
    "query": "energetic scenes with people laughing",
    "limit": 5
  }'
```

### Test 2: Filtered Search
```bash
curl -X POST http://localhost:3001/api/search/scenes \
  -H "Content-Type: application/json" \
  -d '{
    "query": "campaign:abc123",
    "limit": 10
  }'
```

### Test 3: Chat with RAG
```bash
curl -X POST http://localhost:3001/api/chat/message \
  -H "Content-Type: application/json" \
  -d '{
    "conversationId": "conv_123",
    "message": "Show me scenes with happy customers"
  }'
```

---

## ðŸ“ˆ Performance Considerations

### Current Implementation
- **Storage**: Firestore (embeddings + scenes)
- **Search**: In-memory cosine similarity
- **Scalability**: Works well for up to ~10,000 scenes

### For Larger Scale (Future)
If you need to handle 100,000+ scenes, consider:
1. **Vertex AI Vector Search (Matching Engine)**
   - Dedicated vector index infrastructure
   - Sub-second search on billions of vectors
   - Requires additional setup (see below)

2. **Pinecone or Weaviate**
   - Third-party vector databases
   - Easy integration
   - Additional cost

---

## ðŸš€ Advanced: Vertex AI Vector Search Setup (Optional)

For production-scale vector search (100K+ scenes), you can upgrade to Vertex AI Vector Search:

### Requirements:
```bash
# Environment variables (add to .env)
VECTOR_INDEX_ID=projects/YOUR_PROJECT/locations/us-central1/indexes/YOUR_INDEX_ID
VECTOR_INDEX_ENDPOINT=projects/YOUR_PROJECT/locations/us-central1/indexEndpoints/YOUR_ENDPOINT_ID
```

### Setup Steps:
1. Create Matching Engine Index
2. Deploy to Endpoint
3. Update code to use MatchingEngineIndexEndpoint client

**Note**: This is optional and not needed for most use cases!

---

## ðŸŽ“ How to Use in Frontend

### Search Component Example
```typescript
const searchScenes = async (query: string) => {
  const response = await fetch('http://localhost:3001/api/search/scenes', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ query, limit: 10 })
  });
  
  const data = await response.json();
  console.log('Strategy used:', data.strategy); // "semantic" or "filtered"
  return data.results;
};

// Examples:
searchScenes("happy moments");  // Uses vector search
searchScenes("campaign:abc");   // Uses traditional search
```

---

## âœ… Summary

**What You Get:**
âœ… Semantic search that understands meaning, not just keywords
âœ… Intelligent query routing (vector vs traditional)
âœ… Real-time similarity calculations
âœ… No external vector database needed
âœ… Works immediately after setup

**What to Do Next:**
1. Enable the 3 Google Cloud APIs (links above)
2. Create Firestore database
3. Create Cloud Storage bucket
4. Update your `.env` file
5. Start your backend and test!

---

## ðŸ†˜ Troubleshooting

### "Embedding generation failed"
- Check that Vertex AI API is enabled
- Verify service account has "Vertex AI User" role

### "No embeddings found"
- Make sure videos have been processed
- Check Firestore has `embeddings` collection

### "Search returns no results"
- Lower the `minSimilarity` threshold (default: 0.3)
- Check that scenes exist in database

---

**Questions?** Check the logs in `backend/logs/` for detailed error messages!

